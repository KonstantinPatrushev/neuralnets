{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb32bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0e44a9c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.65.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa58fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cb5337f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.2/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 0.4/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 0.6/1.5 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.1/1.5 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 0.0/96.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 96.6/96.6 kB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.6.3-cp311-cp311-win_amd64.whl (268 kB)\n",
      "     ---------------------------------------- 0.0/268.0 kB ? eta -:--:--\n",
      "     ------------------------------------  266.2/268.0 kB 17.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 268.0/268.0 kB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: regex, click, nltk\n",
      "Successfully installed click-8.1.3 nltk-3.8.1 regex-2023.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5138f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cf51a984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0c7e7515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9c2a72cb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (8.0.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipywidgets) (6.19.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipywidgets) (8.12.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (25.0.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.4)\n",
      "Requirement already satisfied: executing in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.5.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (305.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\messi\\anaconda3\\envs\\gpu2\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977c1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import sklearn\n",
    "import datasets\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import torch.nn.functional as f\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from tqdm import tqdm, trange\n",
    "from torchmetrics import Accuracy\n",
    "from ipywidgets import FloatProgress\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61dcf5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(word):\n",
    "    if word in word2idx.keys():\n",
    "        return word2idx[word]\n",
    "    \n",
    "    return word2idx['unk']\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_len = max(len(row['features']) for row in batch)\n",
    "    input_embeds = torch.empty((len(batch), max_len), dtype=torch.long) # матрица фичей для передачи в сеть\n",
    "    labels = torch.empty(len(batch), dtype=torch.long)\n",
    "\n",
    "    for idx, row in enumerate(batch):\n",
    "        to_pad = max_len - len(row['features'])\n",
    "        input_embeds[idx] = torch.cat((row['features'], torch.zeros(to_pad)))\n",
    "        labels[idx] = row['label'] \n",
    "\n",
    "    return {'features': input_embeds, 'labels': labels}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заморозка градиентов на первых N итерациях (для того, чтобы они не вносили неопределенность в веса)\n",
    "\n",
    "def freeze_embeddings(model, req_grad=False):\n",
    "    embeddings = model.embeddings\n",
    "    for c_p in embeddings.parameters():\n",
    "        c_p.requires_grad = req_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ab4e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, criterion, optim, metric, num_epochs, loaders, max_grad_norm=2, num_freeze_iter=1000):\n",
    "    freeze_embeddings(model) # чтобы только на 1 итерации была заморозка\n",
    "    for e in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        pbar = loaders['train']\n",
    "\n",
    "        for batch in pbar:\n",
    "            if num_iter > num_freeze_iter:\n",
    "                freeze_embeddings(model, True)\n",
    "            optimizer.zero_grad()\n",
    "            input_embeds = batch['features'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            pred = model(input_embeds)\n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            if max_grad_norm:\n",
    "                torch.nn.utils.clip_grad_norm(model.parameters(), max_grad_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "            input_embeds.to('cpu')\n",
    "            labels.to('cpu')\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_iter = 0\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in loaders['test']:\n",
    "                input_embeds = batch['features'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                pred = model(input_embeds)\n",
    "\n",
    "                valid_loss += criterion(pred, labels)\n",
    "                valid_acc += metric(pred, labels)\n",
    "                num_iter += 1\n",
    "        \n",
    "        print(f'Valid Loss: {valid_loss / num_iter}, Accuracy: {valid_acc/num_iter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67fc63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование предобученных эмбеддингов\n",
    "# (перед этим передать в model нужную архитектуру, обучить, вызвать этот блок и еще раз обучить)\n",
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            model.embedding.weight[idx] = torch.from_numpy(word2vec.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9152665",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0xDEAD\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e308f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ee4a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (C:/Users/Messi/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38f439068724f5792406c8933bffda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('ag_news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024d4615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Messi\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548\\cache-869cdecf2899d3ea.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = nltk.WordPunctTokenizer()\n",
    "max_length = 128\n",
    "\n",
    "dataset = dataset.map(lambda x: {\n",
    "    'tokenized': tokenizer.tokenize(x['text'])[:max_length]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd169bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = api.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2d23627c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f3b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word: ind for ind, word in enumerate(word2vec.index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b324d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Messi\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548\\cache-b0426b68151d937a.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x:{\n",
    "    'features': [encode(word) for word in x['tokenized']]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71144b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['text', 'tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9baaa802",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d227965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {k: DataLoader(ds, shuffle=(k=='train'), batch_size=32, collate_fn = collate_fn)\n",
    "for k, ds in dataset.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094dc461",
   "metadata": {},
   "source": [
    "# Сверточная нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93b26329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embed_size) # инициализация эмбеддингов для всех слов из словаря\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(embed_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn(x)\n",
    "        pred = self.cls(x)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6b8ea",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd121e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = CNN_Model(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr=1e-2)\n",
    "metric_cnn = Accuracy('multiclass', num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5c002",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46d61b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Messi\\AppData\\Local\\Temp\\ipykernel_18296\\1157182719.py:18: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_grad_norm)\n",
      "  0%|          | 0/1 [01:26<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_network(model_cnn, criterion, optimizer, metric_cnn, \u001b[38;5;241m1\u001b[39m, loaders)\n",
      "Cell \u001b[1;32mIn[16], line 22\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(model, criterion, optim, metric, num_epochs, loaders, max_grad_norm)\u001b[0m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m num_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 22\u001b[0m input_embeds\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_network(model_cnn, criterion, optimizer, metric_cnn, 1, loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77fd266",
   "metadata": {},
   "source": [
    "# Классическая рекуррентная нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3cf65538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_block(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.W = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.U = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.V = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_x = nn.Parameter(torch.rand(1, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.rand(1, hidden_size))\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device) # h(t-1) размер батча x размер скрытого состояния\n",
    "        seq_len = x.size(1) # длина max предложения\n",
    "        \n",
    "        if hidden is None:\n",
    "            for cur_idx in range(seq_len): # обновляем hidden по каждому номеру слова каждого предл-я в батче\n",
    "                hidden = torch.tanh(x[:, cur_idx] @ self.W + hidden @ self.U + self.b_h)\n",
    "#         print(hidden.is_cuda, self.V.is_cuda, self.b_x.is_cuda)\n",
    "        res = torch.tanh(hidden @ self.V + self.b_x)\n",
    "        return res \n",
    "            \n",
    "            \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "08af01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.rnn = RNN_block(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        hidden = self.rnn(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a6d5d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = RNN_Model(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_rnn.parameters(), lr=1e-2)\n",
    "metric_rnn = Accuracy('multiclass', num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ad27767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "c0626268",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  7 16:59:34 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.14                 Driver Version: 531.14       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 960        WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "| 21%   38C    P5               21W / 150W|   1957MiB /  2048MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       564    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      2096    C+G   ..._8wekyb3d8bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      3592    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      7628    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      7932    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9984    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11416      C   ...essi\\anaconda3\\envs\\gpu2\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     13084    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14272    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1da0b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Messi\\AppData\\Local\\Temp\\ipykernel_11416\\1585475611.py:18: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_grad_norm)\n",
      "100%|██████████| 1/1 [00:29<00:00, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss: 1.3884234428405762, Accuracy: 0.2501313090324402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_network(model_rnn, criterion, optimizer, metric, 1, loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0294d",
   "metadata": {},
   "source": [
    "# GRU (модификация RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3541f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.w_rh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_rh = nn.Parameter(torch.rand(1, hidden_size))\n",
    "        self.w_rx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_rx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "        \n",
    "        self.w_zh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_zh = nn.Parameter(torch.rand(1, hidden_size))\n",
    "        self.w_zx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_zx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "        \n",
    "        self.w_nh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_nh = nn.Parameter(torch.rand(1, hidden_size))\n",
    "        self.w_nx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_nx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
    "        \n",
    "        seq_len = x.size(1) \n",
    "        for cur_idx in range(seq_len):\n",
    "            r = torch.sigmoid(x[:, cur_idx] @ self.w_rx + self.b_rx + hidden @ self.w_rh + self.b_rh)\n",
    "            z = torch.sigmoid(x[:, cur_idx] @ self.w_zx + self.b_zx + hidden @ self.w_zh + self.b_zh)\n",
    "            n = torch.tanh(x[:, cur_idx] @ self.w_nx + self.b_nx + r * (hidden @ self.w_nh + self.b_nh))\n",
    "            hidden = (1 - z) * n + z * hidden\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "446c736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Model(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.gru = GRU(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        hidden = self.gru(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05c58953",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = GRU_Model(embed_size=word2vec.vector_size, hidden_size=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_gru.parameters(), lr=1e-2)\n",
    "metric = Accuracy('multiclass', num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "533d376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Messi\\AppData\\Local\\Temp\\ipykernel_18296\\1157182719.py:18: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_grad_norm)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 228.00 MiB (GPU 0; 2.00 GiB total capacity; 1.35 GiB already allocated; 0 bytes free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_network(model_gru, criterion, optimizer, metric, \u001b[38;5;241m1\u001b[39m, loaders)\n",
      "Cell \u001b[1;32mIn[16], line 20\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(model, criterion, optim, metric, num_epochs, loaders, max_grad_norm)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_grad_norm:\n\u001b[0;32m     18\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm(model\u001b[38;5;241m.\u001b[39mparameters(), max_grad_norm)\n\u001b[1;32m---> 20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m num_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     22\u001b[0m input_embeds\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\Lib\\site-packages\\torch\\optim\\adam.py:132\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    129\u001b[0m     state_steps \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m    135\u001b[0m         grads,\n\u001b[0;32m    136\u001b[0m         exp_avgs,\n\u001b[0;32m    137\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[0;32m    141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\Lib\\site-packages\\torch\\optim\\adam.py:92\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[1;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[0;32m     86\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.\u001b[39m)\n\u001b[0;32m     90\u001b[0m )\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Exponential moving average of gradient values\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[0;32m     94\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 228.00 MiB (GPU 0; 2.00 GiB total capacity; 1.35 GiB already allocated; 0 bytes free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "train_network(model_gru, criterion, optimizer, metric, 1, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5ea3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d27ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  7 17:27:33 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.14                 Driver Version: 531.14       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 960        WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "| 21%   40C    P5               24W / 150W|   1430MiB /  2048MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       564    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      2096    C+G   ..._8wekyb3d8bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      3592    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      7628    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      7932    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9984    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13084    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14272    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     18296      C   ...essi\\anaconda3\\envs\\gpu2\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83969f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
